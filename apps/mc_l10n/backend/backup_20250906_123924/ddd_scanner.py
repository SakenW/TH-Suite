#!/usr/bin/env python3
"""
åŸºäºDDDæ¶æ„çš„æ‰«æå™¨æœåŠ¡
å®ç°UPSERTé€»è¾‘ï¼Œé¿å…æ•°æ®é‡å¤
"""
import sqlite3
import json
import zipfile
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
import uuid
import asyncio
import structlog

logger = structlog.get_logger()


class DDDScannerService:
    """ç¬¦åˆDDDè®¾è®¡çš„æ‰«ææœåŠ¡"""
    
    def __init__(self, db_path: str = "mc_l10n_unified.db"):
        self.db_path = db_path
        self.current_scan_id: Optional[str] = None
        self.progress_callback = None
        
    def get_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        conn.execute("PRAGMA foreign_keys = ON")  # å¯ç”¨å¤–é”®çº¦æŸ
        return conn
    
    async def start_scan(
        self, 
        target_path: str, 
        project_id: Optional[str] = None,
        scan_type: str = 'full',
        incremental: bool = True,
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å¯åŠ¨æ‰«æä»»åŠ¡"""
        self.current_scan_id = str(uuid.uuid4())
        project_id = project_id or 'default-project'
        
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            # åˆ›å»ºæ‰«æä¼šè¯
            cursor.execute("""
                INSERT INTO scan_sessions (
                    scan_id, project_id, scan_type, target_path, 
                    status, progress_percent, started_at
                ) VALUES (?, ?, ?, ?, 'scanning', 0, CURRENT_TIMESTAMP)
            """, (self.current_scan_id, project_id, scan_type, target_path))
            
            conn.commit()
            logger.info(f"å¼€å§‹æ‰«æ", scan_id=self.current_scan_id, path=target_path)
            
            # å¼‚æ­¥æ‰§è¡Œæ‰«æ
            asyncio.create_task(self._execute_scan(
                self.current_scan_id, 
                target_path,
                project_id,
                scan_type
            ))
            
            return {
                "scan_id": self.current_scan_id,
                "status": "started",
                "message": "æ‰«æä»»åŠ¡å·²å¯åŠ¨"
            }
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ‰«æä¼šè¯å¤±è´¥: {e}")
            raise
        finally:
            conn.close()
    
    async def _execute_scan(
        self, 
        scan_id: str, 
        target_path: str,
        project_id: str,
        scan_type: str
    ):
        """æ‰§è¡Œæ‰«æä»»åŠ¡"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            path = Path(target_path)
            if not path.exists():
                raise ValueError(f"è·¯å¾„ä¸å­˜åœ¨: {target_path}")
            
            # æŸ¥æ‰¾JARæ–‡ä»¶
            jar_files = list(path.glob("**/*.jar"))
            total_files = len(jar_files)
            
            if total_files == 0:
                logger.warning("æ²¡æœ‰æ‰¾åˆ°JARæ–‡ä»¶")
                self._update_scan_status(scan_id, 'completed', 100, {
                    'total_mods': 0,
                    'total_language_files': 0,
                    'total_keys': 0
                })
                return
            
            logger.info(f"æ‰¾åˆ° {total_files} ä¸ªJARæ–‡ä»¶")
            
            processed = 0
            total_mods = 0
            total_lang_files = 0
            total_keys = 0
            
            for jar_path in jar_files:
                try:
                    # å¤„ç†å•ä¸ªJARæ–‡ä»¶
                    mod_info = await self._process_jar_file(
                        scan_id, 
                        jar_path,
                        project_id
                    )
                    
                    if mod_info:
                        total_mods += 1
                        total_lang_files += mod_info['language_files_count']
                        total_keys += mod_info['total_keys']
                    
                    processed += 1
                    progress = (processed / total_files) * 100
                    
                    # æ›´æ–°è¿›åº¦
                    self._update_scan_progress(scan_id, progress, str(jar_path.name))
                    
                    # è§¦å‘è¿›åº¦å›è°ƒ
                    if self.progress_callback:
                        await self.progress_callback(scan_id, progress, {
                            'current_file': str(jar_path.name),
                            'processed': processed,
                            'total': total_files
                        })
                    
                    await asyncio.sleep(0.01)  # é¿å…é˜»å¡
                    
                except Exception as e:
                    logger.error(f"å¤„ç†JARæ–‡ä»¶å¤±è´¥: {jar_path}", error=str(e))
                    continue
            
            # æ‰«æå®Œæˆï¼Œæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            statistics = {
                'total_mods': total_mods,
                'total_language_files': total_lang_files,
                'total_keys': total_keys,
                'scan_type': scan_type
            }
            
            self._update_scan_status(scan_id, 'completed', 100, statistics)
            
            # å‘å¸ƒé¢†åŸŸäº‹ä»¶
            self._publish_domain_event('ScanCompletedEvent', {
                'scan_id': scan_id,
                'project_id': project_id,
                'statistics': statistics
            })
            
            logger.info(f"æ‰«æå®Œæˆ", scan_id=scan_id, statistics=statistics)
            
        except Exception as e:
            logger.error(f"æ‰«æå¤±è´¥: {e}", scan_id=scan_id)
            self._update_scan_status(scan_id, 'failed', -1, error=str(e))
        finally:
            conn.close()
    
    async def _process_jar_file(
        self, 
        scan_id: str, 
        jar_path: Path,
        project_id: str
    ) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªJARæ–‡ä»¶ï¼ˆå®ç°UPSERTé€»è¾‘ï¼‰"""
        
        try:
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self._calculate_file_hash(jar_path)
            file_size = jar_path.stat().st_size
            
            # æå–æ¨¡ç»„ä¿¡æ¯
            mod_info = self._extract_mod_info(jar_path)
            if not mod_info:
                return None
            
            mod_id = mod_info['mod_id']
            
            conn = self.get_connection()
            cursor = conn.cursor()
            
            # æ£€æŸ¥æ¨¡ç»„æ˜¯å¦å·²å­˜åœ¨
            cursor.execute("""
                SELECT mod_id, file_hash FROM mods WHERE mod_id = ?
            """, (mod_id,))
            existing_mod = cursor.fetchone()
            
            # UPSERTæ¨¡ç»„ä¿¡æ¯
            if existing_mod:
                # æ¨¡ç»„å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
                if existing_mod['file_hash'] != file_hash:
                    # æ–‡ä»¶å·²æ›´æ–°ï¼Œæ›´æ–°æ¨¡ç»„ä¿¡æ¯
                    cursor.execute("""
                        UPDATE mods SET
                            name = ?,
                            display_name = ?,
                            version = ?,
                            minecraft_version = ?,
                            mod_loader = ?,
                            file_path = ?,
                            file_hash = ?,
                            metadata = ?,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE mod_id = ?
                    """, (
                        mod_info['name'],
                        mod_info.get('display_name'),
                        mod_info.get('version'),
                        mod_info.get('minecraft_version'),
                        mod_info.get('mod_loader'),
                        str(jar_path),
                        file_hash,
                        json.dumps(mod_info.get('metadata', {})),
                        mod_id
                    ))
                    logger.info(f"æ›´æ–°æ¨¡ç»„: {mod_id}")
                else:
                    logger.debug(f"æ¨¡ç»„æœªå˜åŒ–ï¼Œè·³è¿‡: {mod_id}")
            else:
                # æ–°æ¨¡ç»„ï¼Œæ’å…¥æ•°æ®
                cursor.execute("""
                    INSERT INTO mods (
                        mod_id, name, display_name, version,
                        minecraft_version, mod_loader, file_path, 
                        file_hash, metadata
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    mod_id,
                    mod_info['name'],
                    mod_info.get('display_name'),
                    mod_info.get('version'),
                    mod_info.get('minecraft_version'),
                    mod_info.get('mod_loader'),
                    str(jar_path),
                    file_hash,
                    json.dumps(mod_info.get('metadata', {}))
                ))
                logger.info(f"æ–°å¢æ¨¡ç»„: {mod_id}")
            
            # å…³è”æ¨¡ç»„åˆ°é¡¹ç›®ï¼ˆå¦‚æœè¿˜æœªå…³è”ï¼‰
            cursor.execute("""
                INSERT OR IGNORE INTO project_mods (
                    project_id, mod_id
                ) VALUES (?, ?)
            """, (project_id, mod_id))
            
            # å¤„ç†è¯­è¨€æ–‡ä»¶
            language_files = self._extract_language_files(jar_path)
            total_keys = 0
            
            for lang_code, lang_content in language_files.items():
                # è®¡ç®—å†…å®¹å“ˆå¸Œ
                content_hash = hashlib.md5(
                    json.dumps(lang_content, sort_keys=True).encode()
                ).hexdigest()
                
                file_id = f"{mod_id}_{lang_code}"
                
                # æ£€æŸ¥è¯­è¨€æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("""
                    SELECT file_id, content_hash FROM language_files 
                    WHERE mod_id = ? AND language_code = ?
                """, (mod_id, lang_code))
                existing_file = cursor.fetchone()
                
                entry_count = len(lang_content)
                total_keys += entry_count
                
                # UPSERTè¯­è¨€æ–‡ä»¶
                if existing_file:
                    if existing_file['content_hash'] != content_hash:
                        # å†…å®¹å·²æ›´æ–°
                        cursor.execute("""
                            UPDATE language_files SET
                                file_path = ?,
                                content_hash = ?,
                                entry_count = ?,
                                last_modified = CURRENT_TIMESTAMP
                            WHERE file_id = ?
                        """, (
                            f"assets/{mod_id}/lang/{lang_code}.json",
                            content_hash,
                            entry_count,
                            file_id
                        ))
                        
                        # æ›´æ–°ç¿»è¯‘æ¡ç›®
                        self._update_translation_entries(
                            cursor, file_id, lang_content
                        )
                        logger.debug(f"æ›´æ–°è¯­è¨€æ–‡ä»¶: {file_id}")
                else:
                    # æ–°è¯­è¨€æ–‡ä»¶
                    cursor.execute("""
                        INSERT INTO language_files (
                            file_id, mod_id, language_code, file_path,
                            file_format, content_hash, entry_count
                        ) VALUES (?, ?, ?, ?, 'json', ?, ?)
                    """, (
                        file_id,
                        mod_id,
                        lang_code,
                        f"assets/{mod_id}/lang/{lang_code}.json",
                        content_hash,
                        entry_count
                    ))
                    
                    # æ’å…¥ç¿»è¯‘æ¡ç›®
                    self._insert_translation_entries(
                        cursor, file_id, lang_content
                    )
                    logger.debug(f"æ–°å¢è¯­è¨€æ–‡ä»¶: {file_id}")
            
            # è®°å½•æ‰«æå‘ç°
            cursor.execute("""
                INSERT INTO scan_discoveries (
                    discovery_id, scan_id, mod_id, mod_name, 
                    mod_version, file_path, file_size,
                    language_files_count, total_keys, is_processed
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, TRUE)
            """, (
                str(uuid.uuid4()),
                scan_id,
                mod_id,
                mod_info['name'],
                mod_info.get('version'),
                str(jar_path),
                file_size,
                len(language_files),
                total_keys
            ))
            
            conn.commit()
            
            return {
                'mod_id': mod_id,
                'language_files_count': len(language_files),
                'total_keys': total_keys
            }
            
        except Exception as e:
            logger.error(f"å¤„ç†JARæ–‡ä»¶å¤±è´¥: {jar_path}", error=str(e))
            return None
        finally:
            if 'conn' in locals():
                conn.close()
    
    def _extract_mod_info(self, jar_path: Path) -> Optional[Dict]:
        """æå–æ¨¡ç»„ä¿¡æ¯"""
        try:
            with zipfile.ZipFile(jar_path, 'r') as jar:
                # å°è¯•ä¸åŒçš„å…ƒæ•°æ®æ–‡ä»¶
                metadata_files = [
                    'META-INF/mods.toml',  # Forge 1.13+
                    'mcmod.info',          # Forge 1.12-
                    'fabric.mod.json',     # Fabric
                    'quilt.mod.json'       # Quilt
                ]
                
                for meta_file in metadata_files:
                    if meta_file in jar.namelist():
                        content = jar.read(meta_file).decode('utf-8', errors='ignore')
                        
                        # è§£æä¸åŒæ ¼å¼çš„å…ƒæ•°æ®
                        if meta_file.endswith('.json'):
                            data = json.loads(content)
                            return self._parse_json_metadata(data, meta_file)
                        elif meta_file.endswith('.toml'):
                            # ç®€å•çš„TOMLè§£æ
                            return self._parse_toml_metadata(content)
                
                # å¦‚æœæ²¡æœ‰å…ƒæ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ–‡ä»¶åä½œä¸ºæ¨¡ç»„ID
                mod_id = jar_path.stem.lower().replace(' ', '_')
                return {
                    'mod_id': mod_id,
                    'name': jar_path.stem,
                    'version': 'unknown',
                    'mod_loader': 'unknown'
                }
                
        except Exception as e:
            logger.error(f"æå–æ¨¡ç»„ä¿¡æ¯å¤±è´¥: {jar_path}", error=str(e))
            return None
    
    def _parse_json_metadata(self, data: Any, filename: str) -> Dict:
        """è§£æJSONæ ¼å¼çš„æ¨¡ç»„å…ƒæ•°æ®"""
        if 'fabric.mod.json' in filename or 'quilt.mod.json' in filename:
            # Fabric/Quiltæ ¼å¼
            return {
                'mod_id': data.get('id', 'unknown'),
                'name': data.get('name', data.get('id', 'Unknown')),
                'display_name': data.get('name'),
                'version': data.get('version', 'unknown'),
                'minecraft_version': self._extract_mc_version(data),
                'mod_loader': 'fabric' if 'fabric' in filename else 'quilt',
                'metadata': data
            }
        else:
            # è€ç‰ˆForgeæ ¼å¼ (mcmod.info)
            if isinstance(data, list) and len(data) > 0:
                data = data[0]
            
            return {
                'mod_id': data.get('modid', 'unknown'),
                'name': data.get('name', 'Unknown'),
                'display_name': data.get('name'),
                'version': data.get('version', 'unknown'),
                'minecraft_version': data.get('mcversion'),
                'mod_loader': 'forge',
                'metadata': data
            }
    
    def _parse_toml_metadata(self, content: str) -> Dict:
        """ç®€å•è§£æTOMLæ ¼å¼çš„æ¨¡ç»„å…ƒæ•°æ®"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„TOMLè§£æå™¨
        mod_info = {
            'mod_loader': 'forge',
            'metadata': {}
        }
        
        for line in content.split('\n'):
            line = line.strip()
            if '=' in line and not line.startswith('#'):
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                
                if 'modId' in key:
                    mod_info['mod_id'] = value
                elif 'displayName' in key:
                    mod_info['name'] = value
                    mod_info['display_name'] = value
                elif key == 'version':
                    mod_info['version'] = value
        
        return mod_info or {
            'mod_id': 'unknown',
            'name': 'Unknown',
            'version': 'unknown',
            'mod_loader': 'forge'
        }
    
    def _extract_mc_version(self, data: Dict) -> Optional[str]:
        """æå–Minecraftç‰ˆæœ¬"""
        if 'depends' in data:
            for dep in data['depends']:
                if dep == 'minecraft' or (isinstance(dep, dict) and dep.get('id') == 'minecraft'):
                    if isinstance(dep, dict):
                        return dep.get('version')
        return None
    
    def _extract_language_files(self, jar_path: Path) -> Dict[str, Dict]:
        """æå–è¯­è¨€æ–‡ä»¶å†…å®¹"""
        language_files = {}
        
        try:
            with zipfile.ZipFile(jar_path, 'r') as jar:
                # æŸ¥æ‰¾è¯­è¨€æ–‡ä»¶
                for file_name in jar.namelist():
                    # åŒ¹é…è¯­è¨€æ–‡ä»¶è·¯å¾„æ¨¡å¼
                    if '/lang/' in file_name and file_name.endswith('.json'):
                        # æå–è¯­è¨€ä»£ç 
                        lang_code = Path(file_name).stem
                        
                        try:
                            content = jar.read(file_name).decode('utf-8')
                            lang_data = json.loads(content)
                            
                            if isinstance(lang_data, dict) and lang_data:
                                language_files[lang_code] = lang_data
                                
                        except Exception as e:
                            logger.debug(f"è§£æè¯­è¨€æ–‡ä»¶å¤±è´¥: {file_name}", error=str(e))
                            continue
                            
        except Exception as e:
            logger.error(f"æå–è¯­è¨€æ–‡ä»¶å¤±è´¥: {jar_path}", error=str(e))
        
        return language_files
    
    def _insert_translation_entries(
        self, 
        cursor: sqlite3.Cursor, 
        file_id: str, 
        entries: Dict[str, str]
    ):
        """æ’å…¥ç¿»è¯‘æ¡ç›®"""
        for key, value in entries.items():
            entry_id = str(uuid.uuid4())
            key_type = self._detect_key_type(key)
            
            cursor.execute("""
                INSERT OR IGNORE INTO translation_entries (
                    entry_id, file_id, translation_key, key_type,
                    original_value, translated_value, status
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                entry_id,
                file_id,
                key,
                key_type,
                value,
                value,  # åˆå§‹æ—¶åŸæ–‡å’Œè¯‘æ–‡ç›¸åŒ
                'untranslated' if file_id.endswith('_en_us') else 'translated'
            ))
    
    def _update_translation_entries(
        self, 
        cursor: sqlite3.Cursor, 
        file_id: str, 
        entries: Dict[str, str]
    ):
        """æ›´æ–°ç¿»è¯‘æ¡ç›®ï¼ˆä¿ç•™ç”¨æˆ·ä¿®æ”¹ï¼‰"""
        # è·å–ç°æœ‰æ¡ç›®
        cursor.execute("""
            SELECT translation_key, translated_value, status 
            FROM translation_entries 
            WHERE file_id = ?
        """, (file_id,))
        
        existing = {row['translation_key']: row for row in cursor.fetchall()}
        
        for key, value in entries.items():
            if key in existing:
                # åªæ›´æ–°åŸæ–‡ï¼Œä¿ç•™ç”¨æˆ·çš„ç¿»è¯‘
                cursor.execute("""
                    UPDATE translation_entries 
                    SET original_value = ?, last_modified = CURRENT_TIMESTAMP
                    WHERE file_id = ? AND translation_key = ?
                """, (value, file_id, key))
            else:
                # æ–°é”®ï¼Œæ’å…¥
                self._insert_translation_entries(cursor, file_id, {key: value})
        
        # æ ‡è®°å·²åˆ é™¤çš„é”®
        deleted_keys = set(existing.keys()) - set(entries.keys())
        for key in deleted_keys:
            cursor.execute("""
                UPDATE translation_entries 
                SET status = 'deleted', last_modified = CURRENT_TIMESTAMP
                WHERE file_id = ? AND translation_key = ?
            """, (file_id, key))
    
    def _detect_key_type(self, key: str) -> str:
        """æ£€æµ‹ç¿»è¯‘é”®ç±»å‹"""
        if key.startswith('item.'):
            return 'item'
        elif key.startswith('block.'):
            return 'block'
        elif key.startswith('entity.'):
            return 'entity'
        elif key.startswith('gui.'):
            return 'gui'
        elif key.startswith('tooltip.'):
            return 'tooltip'
        else:
            return 'other'
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        hasher = hashlib.md5()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b''):
                hasher.update(chunk)
        return hasher.hexdigest()
    
    def _update_scan_progress(self, scan_id: str, progress: float, current_item: str):
        """æ›´æ–°æ‰«æè¿›åº¦"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                UPDATE scan_sessions 
                SET progress_percent = ?, current_item = ?
                WHERE scan_id = ?
            """, (progress, current_item, scan_id))
            conn.commit()
        finally:
            conn.close()
    
    def _update_scan_status(
        self, 
        scan_id: str, 
        status: str, 
        progress: float,
        statistics: Optional[Dict] = None,
        error: Optional[str] = None
    ):
        """æ›´æ–°æ‰«æçŠ¶æ€"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            if status == 'completed':
                cursor.execute("""
                    UPDATE scan_sessions 
                    SET status = ?, progress_percent = ?, 
                        statistics = ?, completed_at = CURRENT_TIMESTAMP
                    WHERE scan_id = ?
                """, (status, progress, json.dumps(statistics), scan_id))
            elif status == 'failed':
                cursor.execute("""
                    UPDATE scan_sessions 
                    SET status = ?, error_message = ?, 
                        completed_at = CURRENT_TIMESTAMP
                    WHERE scan_id = ?
                """, (status, error, scan_id))
            else:
                cursor.execute("""
                    UPDATE scan_sessions 
                    SET status = ?, progress_percent = ?
                    WHERE scan_id = ?
                """, (status, progress, scan_id))
            
            conn.commit()
        finally:
            conn.close()
    
    def _publish_domain_event(self, event_type: str, event_data: Dict):
        """å‘å¸ƒé¢†åŸŸäº‹ä»¶"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                INSERT INTO domain_events (
                    event_id, event_type, event_data, occurred_at
                ) VALUES (?, ?, ?, CURRENT_TIMESTAMP)
            """, (
                str(uuid.uuid4()),
                event_type,
                json.dumps(event_data)
            ))
            conn.commit()
        finally:
            conn.close()
    
    async def get_scan_status(self, scan_id: str) -> Dict:
        """è·å–æ‰«æçŠ¶æ€"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT * FROM scan_sessions WHERE scan_id = ?
            """, (scan_id,))
            
            session = cursor.fetchone()
            if not session:
                return {'status': 'not_found'}
            
            result = dict(session)
            
            # è§£æJSONå­—æ®µ
            if result.get('statistics'):
                result['statistics'] = json.loads(result['statistics'])
            
            # è·å–å‘ç°çš„æ¨¡ç»„æ•°é‡
            cursor.execute("""
                SELECT COUNT(*) as count FROM scan_discoveries 
                WHERE scan_id = ?
            """, (scan_id,))
            discoveries = cursor.fetchone()
            result['discovered_mods'] = discoveries['count']
            
            return result
            
        finally:
            conn.close()


# å…¨å±€å®ä¾‹
_scanner_instance = None


async def init_ddd_scanner(db_path: str = "mc_l10n_unified.db"):
    """åˆå§‹åŒ–DDDæ‰«æå™¨"""
    global _scanner_instance
    _scanner_instance = DDDScannerService(db_path)
    logger.info(f"âœ… DDD Scanner initialized with database: {db_path}")
    return _scanner_instance


def get_scanner():
    """è·å–æ‰«æå™¨å®ä¾‹"""
    return _scanner_instance


# æµ‹è¯•å‡½æ•°
async def test_ddd_scanner():
    """æµ‹è¯•DDDæ‰«æå™¨"""
    scanner = DDDScannerService()
    
    # æµ‹è¯•è·¯å¾„
    test_path = "/home/saken/Games/Curseforge/Minecraft/Instances/DeceasedCraft - Modern Zombie Apocalypse/mods"
    
    print(f"ğŸš€ å¼€å§‹æµ‹è¯•DDDæ‰«æå™¨...")
    print(f"ğŸ“ æ‰«æè·¯å¾„: {test_path}")
    
    # å¯åŠ¨æ‰«æ
    scan_id = await scanner.start_scan(test_path, scan_type='full')
    print(f"ğŸ“‹ æ‰«æID: {scan_id}")
    
    # ç­‰å¾…æ‰«æå®Œæˆ
    while True:
        status = await scanner.get_scan_status(scan_id)
        progress = status.get('progress_percent', 0)
        
        print(f"â³ è¿›åº¦: {progress:.1f}% - çŠ¶æ€: {status.get('status')}")
        
        if status.get('status') in ['completed', 'failed']:
            break
        
        await asyncio.sleep(1)
    
    # æ˜¾ç¤ºç»“æœ
    if status.get('status') == 'completed':
        stats = status.get('statistics', {})
        print(f"\nâœ… æ‰«æå®Œæˆ!")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   - æ¨¡ç»„æ•°é‡: {stats.get('total_mods', 0)}")
        print(f"   - è¯­è¨€æ–‡ä»¶: {stats.get('total_language_files', 0)}")
        print(f"   - ç¿»è¯‘é”®æ•°: {stats.get('total_keys', 0)}")
    else:
        print(f"\nâŒ æ‰«æå¤±è´¥: {status.get('error_message')}")


if __name__ == "__main__":
    asyncio.run(test_ddd_scanner())