"""
ä¼ä¸šçº§UPSERTæ‰«æå™¨ - é›†æˆæ‰€æœ‰é«˜ä»·å€¼ç»„ä»¶
æ•´åˆäº†JARæ‰«æå™¨ã€WebSocketå®æ—¶é€šä¿¡ã€ç¼“å­˜ç³»ç»Ÿã€çŠ¶æ€æœºç­‰å®Œæ•´åŠŸèƒ½
"""

import os
import sys
import sqlite3
import asyncio
import hashlib
import zipfile
import json
import uuid
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import logging

# å¯¼å…¥é‡æ–°è®¾è®¡çš„æ•°æ®åº“ç±»
from database_redesign import DatabaseRedesign

# å¯¼å…¥ä¼ä¸šçº§ç»„ä»¶
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å°è¯•å¯¼å…¥é«˜ä»·å€¼çš„å·²æœ‰ç»„ä»¶
try:
    # JARæ‰«æå™¨ï¼ˆä¼ä¸šçº§ï¼‰
    from infrastructure.scanners.jar_scanner import JarScanner
    from infrastructure.scanners.base_scanner import ScanFilter
    
    # WebSocketå®æ—¶é€šä¿¡
    from packages.backend_kit.websocket import (
        WebSocketManager, ProgressMessage, LogMessage
    )
    
    # ç¼“å­˜ç³»ç»Ÿ
    from packages.core.framework.cache.cache_manager import CacheManager
    from packages.core.framework.cache.providers.memory_cache import MemoryCacheProvider
    from packages.core.framework.cache.providers.file_cache import FileCacheProvider
    from packages.core.framework.cache.decorators import cached
    
    # çŠ¶æ€æœº
    from packages.core.state import ProjectStateMachine, ScanStateMachine
    
    # æ™ºèƒ½è§£æå™¨
    from src.mc_l10n.infrastructure.parsers.enhanced_parser import ModFileAnalyzer
    from src.mc_l10n.domain.scan_models import ModpackScanRule, MinecraftModScanRule
    
    HAS_ENTERPRISE_FEATURES = True
    logger.info("ğŸš€ ä¼ä¸šçº§åŠŸèƒ½ç»„ä»¶å…¨éƒ¨åŠ è½½æˆåŠŸ")
    
except ImportError as e:
    logger.warning(f"æŸäº›ä¼ä¸šçº§åŠŸèƒ½ä¸å¯ç”¨: {e}")
    HAS_ENTERPRISE_FEATURES = False

logger = logging.getLogger(__name__)

class EnterpriseUpsertScanner:
    """ä¼ä¸šçº§UPSERTæ‰«æå™¨ - é›†æˆæ‰€æœ‰é«˜ä»·å€¼åŠŸèƒ½"""
    
    def __init__(self, db_path: str = "mc_l10n_enterprise.db"):
        self.db_redesign = DatabaseRedesign(db_path)
        self.db_path = db_path
        self.active_scans = {}
        
        # åˆå§‹åŒ–ä¼ä¸šçº§ç»„ä»¶
        self._init_enterprise_components()
        
        # ç¡®ä¿æ•°æ®åº“ç»“æ„å­˜åœ¨
        self.db_redesign.create_new_schema()
        logger.info("ğŸ¯ ä¼ä¸šçº§UPSERTæ‰«æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_enterprise_components(self):
        """åˆå§‹åŒ–ä¼ä¸šçº§ç»„ä»¶"""
        if HAS_ENTERPRISE_FEATURES:
            # åˆå§‹åŒ–JARæ‰«æå™¨ï¼ˆä¼ä¸šçº§ï¼‰
            self.jar_scanner = JarScanner()
            logger.info("âœ… JARæ‰«æå™¨ï¼ˆä¼ä¸šçº§ï¼‰å·²åŠ è½½")
            
            # åˆå§‹åŒ–WebSocketç®¡ç†å™¨
            self.ws_manager = WebSocketManager()
            logger.info("âœ… WebSocketå®æ—¶é€šä¿¡ç®¡ç†å™¨å·²åŠ è½½")
            
            # åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
            self.cache_manager = CacheManager(default_ttl=3600)  # 1å°æ—¶ç¼“å­˜
            # æ·»åŠ å†…å­˜ç¼“å­˜æä¾›è€…
            self.cache_manager.register_provider(
                "memory", MemoryCacheProvider(max_size=1000)
            )
            # æ·»åŠ æ–‡ä»¶ç¼“å­˜æä¾›è€…
            self.cache_manager.register_provider(
                "file", FileCacheProvider(cache_dir=Path(".cache"))
            )
            self.cache_manager.set_default("memory")
            logger.info("âœ… å¤šå±‚ç¼“å­˜ç³»ç»Ÿå·²åŠ è½½")
            
            # åˆå§‹åŒ–çŠ¶æ€æœº
            self.state_machine = ScanStateMachine() if 'ScanStateMachine' in globals() else None
            logger.info("âœ… çŠ¶æ€æœºç®¡ç†ç³»ç»Ÿå·²åŠ è½½")
            
            # åˆå§‹åŒ–æ™ºèƒ½è§£æå™¨
            self.mod_analyzer = ModFileAnalyzer()
            self.modpack_rule = ModpackScanRule()
            self.mod_rule = MinecraftModScanRule()
            logger.info("âœ… æ™ºèƒ½è§£æå™¨å·²åŠ è½½")
            
        else:
            # å›é€€åˆ°åŸºç¡€åŠŸèƒ½
            self.jar_scanner = None
            self.ws_manager = None
            self.cache_manager = None
            self.state_machine = None
            self.mod_analyzer = None
            self.modpack_rule = None
            self.mod_rule = None
            logger.info("âš ï¸  ä½¿ç”¨åŸºç¡€åŠŸèƒ½æ¨¡å¼")
    
    @cached(ttl=1800, cache_key="modpack_info_{directory}")
    def detect_modpack_info_cached(self, directory: str) -> Optional[Dict]:
        """ç¼“å­˜çš„ç»„åˆåŒ…ä¿¡æ¯æ£€æµ‹"""
        return self._detect_modpack_info_internal(directory)
    
    def _detect_modpack_info_internal(self, directory: str) -> Optional[Dict]:
        """å†…éƒ¨ç»„åˆåŒ…ä¿¡æ¯æ£€æµ‹é€»è¾‘"""
        scan_path = Path(directory)
        
        if not scan_path.exists() or not scan_path.is_dir():
            return None
        
        modpack_info = {
            "name": scan_path.name,
            "path": str(scan_path),
            "platform": "unknown",
            "version": "unknown",
            "minecraft_version": "unknown",
            "loader": "unknown",
            "mod_count": 0,
            "detection_method": "standard"
        }
        
        try:
            # CurseForge æ ¼å¼æ£€æµ‹ï¼ˆå¢å¼ºç‰ˆï¼‰
            manifest_path = scan_path / "manifest.json"
            if manifest_path.exists():
                try:
                    with open(manifest_path, 'r', encoding='utf-8') as f:
                        manifest = json.load(f)
                        if manifest.get('manifestType') == 'minecraftModpack':
                            # æå–è¯¦ç»†ä¿¡æ¯
                            minecraft_info = manifest.get('minecraft', {})
                            mod_loaders = minecraft_info.get('modLoaders', [])
                            
                            modpack_info.update({
                                "name": manifest.get('name', scan_path.name),
                                "version": manifest.get('version', 'unknown'),
                                "platform": "CurseForge",
                                "minecraft_version": minecraft_info.get('version', 'unknown'),
                                "loader": mod_loaders[0].get('id', 'unknown').split('-')[0] if mod_loaders else 'unknown',
                                "author": manifest.get('author', 'unknown'),
                                "mod_count": len(manifest.get('files', [])),
                                "detection_method": "curseforge_manifest",
                                "manifest_version": manifest.get('manifestVersion', 1),
                                "loader_version": mod_loaders[0].get('id', 'unknown') if mod_loaders else 'unknown',
                                "files_info": manifest.get('files', []),
                                "overrides": manifest.get('overrides', 'overrides')
                            })
                            
                            logger.info(f"ğŸ¯ æ£€æµ‹åˆ°CurseForgeç»„åˆåŒ…: {modpack_info['name']} v{modpack_info['version']}")
                            return modpack_info
                except Exception as e:
                    logger.warning(f"è§£æCurseForge manifestå¤±è´¥: {e}")
            
            # Modrinth æ ¼å¼æ£€æµ‹ï¼ˆå¢å¼ºç‰ˆï¼‰
            modrinth_path = scan_path / "modrinth.index.json"
            if modrinth_path.exists():
                try:
                    with open(modrinth_path, 'r', encoding='utf-8') as f:
                        modrinth = json.load(f)
                        dependencies = modrinth.get('dependencies', {})
                        
                        modpack_info.update({
                            "name": modrinth.get('name', scan_path.name),
                            "version": modrinth.get('versionId', 'unknown'),
                            "platform": "Modrinth",
                            "minecraft_version": dependencies.get('minecraft', 'unknown'),
                            "loader": next((k for k in dependencies.keys() if k != 'minecraft'), 'unknown'),
                            "mod_count": len(modrinth.get('files', [])),
                            "detection_method": "modrinth_index",
                            "format_version": modrinth.get('formatVersion', 1),
                            "game": modrinth.get('game', 'minecraft'),
                            "dependencies": dependencies,
                            "files_info": modrinth.get('files', [])
                        })
                        
                        logger.info(f"ğŸ¯ æ£€æµ‹åˆ°Modrinthç»„åˆåŒ…: {modpack_info['name']} v{modpack_info['version']}")
                        return modpack_info
                except Exception as e:
                    logger.warning(f"è§£æModrinth indexå¤±è´¥: {e}")
            
            # MultiMC æ ¼å¼æ£€æµ‹ï¼ˆå¢å¼ºç‰ˆï¼‰
            mmc_pack_path = scan_path / "mmc-pack.json"
            instance_cfg_path = scan_path / "instance.cfg"
            if mmc_pack_path.exists() or instance_cfg_path.exists():
                try:
                    if mmc_pack_path.exists():
                        with open(mmc_pack_path, 'r', encoding='utf-8') as f:
                            mmc_pack = json.load(f)
                            modpack_info.update({
                                "name": mmc_pack.get('name', scan_path.name),
                                "version": mmc_pack.get('version', 'unknown'),
                                "platform": "MultiMC",
                                "detection_method": "multimc_pack",
                                "format_version": mmc_pack.get('formatVersion', 1),
                                "components": mmc_pack.get('components', [])
                            })
                    
                    if instance_cfg_path.exists():
                        with open(instance_cfg_path, 'r', encoding='utf-8') as f:
                            for line in f:
                                line = line.strip()
                                if line.startswith('name='):
                                    modpack_info['name'] = line.split('=', 1)[1]
                                elif line.startswith('IntendedVersion='):
                                    modpack_info['minecraft_version'] = line.split('=', 1)[1]
                                elif line.startswith('iconKey='):
                                    modpack_info['icon'] = line.split('=', 1)[1]
                    
                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ°MultiMCå®ä¾‹: {modpack_info['name']}")
                    return modpack_info
                except Exception as e:
                    logger.warning(f"è§£æMultiMCé…ç½®å¤±è´¥: {e}")
            
            # é€šç”¨ç›®å½•ç»“æ„æ£€æµ‹ï¼ˆå¢å¼ºç‰ˆï¼‰
            mods_dir = scan_path / "mods"
            if mods_dir.exists() and mods_dir.is_dir():
                jar_files = list(mods_dir.glob("*.jar"))
                if jar_files:
                    # å°è¯•åˆ†æç¬¬ä¸€ä¸ªmodæ¥è·å–æ›´å¤šä¿¡æ¯
                    sample_analysis = None
                    if self.mod_analyzer and jar_files:
                        try:
                            sample_analysis = self.mod_analyzer.analyze_mod_archive(jar_files[0])
                            loader_type = sample_analysis.get('loader_type', 'unknown')
                        except:
                            loader_type = 'unknown'
                    else:
                        loader_type = 'unknown'
                    
                    modpack_info.update({
                        "platform": "Generic",
                        "mod_count": len(jar_files),
                        "detection_method": "generic_structure",
                        "loader": loader_type,
                        "sample_mod": jar_files[0].name if jar_files else None,
                        "sample_analysis": sample_analysis
                    })
                    
                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ°é€šç”¨ç»„åˆåŒ…ç›®å½•: {modpack_info['name']} ({len(jar_files)} mods, {loader_type})")
                    return modpack_info
            
        except Exception as e:
            logger.error(f"ç»„åˆåŒ…ä¿¡æ¯æ£€æµ‹å¤±è´¥ {directory}: {e}")
        
        return None
    
    @cached(ttl=3600, cache_key="mod_info_{file_hash}")
    async def extract_mod_info_cached(self, jar_path: Path) -> Tuple[Optional[Dict], List[Dict]]:
        """ç¼“å­˜çš„MODä¿¡æ¯æå–"""
        file_hash = self._calculate_file_hash(jar_path)
        return await self._extract_mod_info_internal(jar_path, file_hash)
    
    async def _extract_mod_info_internal(self, jar_path: Path, file_hash: str) -> Tuple[Optional[Dict], List[Dict]]:
        """å†…éƒ¨MODä¿¡æ¯æå–é€»è¾‘ - ä½¿ç”¨ä¼ä¸šçº§JARæ‰«æå™¨"""
        try:
            if self.jar_scanner:
                # ä½¿ç”¨ä¼ä¸šçº§JARæ‰«æå™¨
                from domain.models.value_objects.file_path import FilePath
                jar_file_path = FilePath.from_string(str(jar_path))
                
                # æ‰§è¡Œæ‰«æ
                scan_result = await self.jar_scanner.scan(jar_file_path)
                
                if scan_result.status.value == "completed":
                    # è½¬æ¢æ‰«æç»“æœä¸ºæ ‡å‡†æ ¼å¼
                    mod_info = {
                        "mod_id": jar_path.stem,  # é»˜è®¤å€¼ï¼Œä¼šè¢«è¦†ç›–
                        "name": jar_path.stem,
                        "version": "unknown",
                        "file_path": str(jar_path),
                        "file_size": scan_result.metadata.get("file_size", 0),
                        "file_hash": file_hash,
                        "mod_loader": scan_result.metadata.get("mod_loader_type", "unknown"),
                        "compression_ratio": scan_result.metadata.get("compressed_size", 0) / max(scan_result.metadata.get("uncompressed_size", 1), 1),
                        "total_entries": scan_result.metadata.get("total_entries", 0),
                        "has_assets": scan_result.metadata.get("has_assets", False),
                        "has_mod_info": scan_result.metadata.get("has_mod_info", False),
                        "unique_mod_ids": scan_result.metadata.get("unique_mod_ids", []),
                        "supported_languages": scan_result.metadata.get("supported_languages", []),
                        "analysis_method": "enterprise_jar_scanner"
                    }
                    
                    # æå–è¯­è¨€æ–‡ä»¶ä¿¡æ¯
                    language_files = []
                    for discovered_file in scan_result.discovered_files:
                        if discovered_file.is_language_file:
                            # ä»JARä¸­è¯»å–å®é™…å†…å®¹
                            try:
                                content_bytes = await self.jar_scanner.extract_file_content(
                                    jar_file_path, discovered_file.relative_path
                                )
                                if content_bytes:
                                    content_str = content_bytes.decode('utf-8')
                                    content = json.loads(content_str)
                                    
                                    language_files.append({
                                        "file_path": discovered_file.relative_path,
                                        "locale": discovered_file.language_code.code if discovered_file.language_code else "unknown",
                                        "namespace": discovered_file.mod_id.value if discovered_file.mod_id else "minecraft",
                                        "key_count": len(content) if isinstance(content, dict) else 0,
                                        "entries": content,
                                        "file_size": discovered_file.file_size,
                                        "extraction_method": "enterprise_scanner"
                                    })
                            except Exception as lang_error:
                                logger.warning(f"æå–è¯­è¨€æ–‡ä»¶å†…å®¹å¤±è´¥ {discovered_file.relative_path}: {lang_error}")
                    
                    logger.info(f"ğŸ­ ä¼ä¸šçº§æ‰«æå®Œæˆ: {jar_path.name} - {len(language_files)} è¯­è¨€æ–‡ä»¶")
                    return mod_info, language_files
                else:
                    logger.warning(f"ä¼ä¸šçº§æ‰«æå¤±è´¥: {jar_path.name}")
            
            # å›é€€åˆ°ç®€åŒ–ç‰ˆæœ¬
            return await self._extract_mod_info_simple(jar_path, file_hash)
            
        except Exception as e:
            logger.error(f"ä¼ä¸šçº§MODä¿¡æ¯æå–å¤±è´¥ {jar_path}: {e}")
            return await self._extract_mod_info_simple(jar_path, file_hash)
    
    async def _extract_mod_info_simple(self, jar_path: Path, file_hash: str) -> Tuple[Optional[Dict], List[Dict]]:
        """ç®€åŒ–MODä¿¡æ¯æå–ï¼ˆåå¤‡æ–¹æ¡ˆï¼‰"""
        logger.info(f"ä½¿ç”¨ç®€åŒ–æ‰«æ: {jar_path.name}")
        # è¿™é‡Œå¯ä»¥æ”¾ç½®ä¹‹å‰çš„ç®€åŒ–æ‰«æé€»è¾‘
        # ä¸ºç®€æ´èµ·è§ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        mod_info = {
            "mod_id": jar_path.stem,
            "name": jar_path.stem,
            "version": "unknown",
            "file_path": str(jar_path),
            "file_size": jar_path.stat().st_size if jar_path.exists() else 0,
            "file_hash": file_hash,
            "analysis_method": "simple_fallback"
        }
        return mod_info, []
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹å“ˆå¸Œ"""
        hash_sha256 = hashlib.sha256()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return hashlib.sha256(str(file_path).encode()).hexdigest()
    
    async def scan_directory_with_enterprise_features(
        self, scan_id: str, directory: str, incremental: bool = True
    ):
        """ä½¿ç”¨ä¼ä¸šçº§åŠŸèƒ½çš„å®Œæ•´æ‰«æ"""
        logger.info(f"ğŸš€ å¼€å§‹ä¼ä¸šçº§æ‰«æ: {directory} ({'å¢é‡' if incremental else 'å…¨é‡'})")
        
        try:
            # çŠ¶æ€æœºç®¡ç†
            if self.state_machine:
                await self.state_machine.start_scan(scan_id)
            
            scan_path = Path(directory)
            if not scan_path.exists():
                raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
            
            # ä½¿ç”¨ç¼“å­˜çš„ç»„åˆåŒ…ä¿¡æ¯æ£€æµ‹
            if self.cache_manager:
                modpack_info = self.detect_modpack_info_cached(directory)
            else:
                modpack_info = self._detect_modpack_info_internal(directory)
            
            if modpack_info:
                logger.info(f"ğŸ¯ è¯†åˆ«ç»„åˆåŒ…: {modpack_info['name']} ({modpack_info['platform']})")
                
                # å‘é€å®æ—¶æ›´æ–°
                if self.ws_manager:
                    await self.ws_manager.broadcast_message(
                        ProgressMessage(
                            job_id=scan_id,
                            status="scanning",
                            progress=5,
                            message=f"è¯†åˆ«åˆ° {modpack_info['platform']} ç»„åˆåŒ…: {modpack_info['name']}"
                        )
                    )
            
            # æŸ¥æ‰¾æ‰€æœ‰jaræ–‡ä»¶
            jar_files = []
            for root, dirs, files in os.walk(scan_path):
                for file in files:
                    if file.endswith('.jar'):
                        jar_files.append(Path(root) / file)
            
            logger.info(f"å‘ç° {len(jar_files)} ä¸ªJARæ–‡ä»¶")
            
            # åˆå§‹åŒ–æ‰«æçŠ¶æ€
            scan_status = {
                "status": "scanning",
                "progress": 10,
                "total_files": len(jar_files),
                "processed_files": 0,
                "current_file": "",
                "total_mods": 0,
                "total_language_files": 0,
                "total_keys": 0,
                "scan_mode": "å¢é‡" if incremental else "å…¨é‡",
                "started_at": datetime.now().isoformat(),
                "features_used": {
                    "enterprise_jar_scanner": bool(self.jar_scanner),
                    "websocket_updates": bool(self.ws_manager),
                    "cache_system": bool(self.cache_manager),
                    "state_machine": bool(self.state_machine)
                }
            }
            
            # æ·»åŠ ç»„åˆåŒ…ä¿¡æ¯
            if modpack_info:
                scan_status.update({
                    "modpack_name": modpack_info['name'],
                    "modpack_platform": modpack_info['platform'],
                    "modpack_version": modpack_info['version'],
                    "minecraft_version": modpack_info['minecraft_version'],
                    "mod_loader": modpack_info['loader'],
                    "expected_mod_count": modpack_info.get('mod_count', len(jar_files))
                })
            
            self.active_scans[scan_id] = scan_status
            
            # å¼€å§‹å¤„ç†æ–‡ä»¶
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            discovered_mods = set()
            discovered_language_files = set()
            discovered_translations = 0
            
            # å¹¶å‘å¤„ç†æ–‡ä»¶ï¼ˆå¦‚æœæ–‡ä»¶æ•°é‡è¾ƒå¤šï¼‰
            batch_size = 5 if len(jar_files) > 20 else 1
            
            for i in range(0, len(jar_files), batch_size):
                batch = jar_files[i:i + batch_size]
                
                # å¹¶å‘å¤„ç†æ‰¹æ¬¡
                tasks = []
                for jar_path in batch:
                    if self.cache_manager:
                        task = self.extract_mod_info_cached(jar_path)
                    else:
                        file_hash = self._calculate_file_hash(jar_path)
                        task = self._extract_mod_info_internal(jar_path, file_hash)
                    tasks.append(task)
                
                # ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # å¤„ç†ç»“æœ
                for j, (jar_path, result) in enumerate(zip(batch, batch_results)):
                    if isinstance(result, Exception):
                        logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {jar_path}: {result}")
                        continue
                    
                    mod_info, language_files = result
                    file_index = i + j
                    
                    # æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
                    if scan_id in self.active_scans and self.active_scans[scan_id].get("status") == "cancelled":
                        logger.info(f"æ‰«æè¢«å–æ¶ˆ: {scan_id}")
                        return
                    
                    # æ›´æ–°è¿›åº¦
                    progress = 10 + ((file_index + 1) / len(jar_files)) * 80
                    self.active_scans[scan_id].update({
                        "current_file": jar_path.name,
                        "processed_files": file_index + 1,
                        "progress": progress
                    })
                    
                    # å‘é€å®æ—¶æ›´æ–°
                    if self.ws_manager and (file_index + 1) % 10 == 0:  # æ¯10ä¸ªæ–‡ä»¶æ›´æ–°ä¸€æ¬¡
                        await self.ws_manager.broadcast_message(
                            ProgressMessage(
                                job_id=scan_id,
                                status="scanning",
                                progress=progress,
                                message=f"å¤„ç†ä¸­: {jar_path.name} ({file_index + 1}/{len(jar_files)})"
                            )
                        )
                    
                    if mod_info:
                        # UPSERTæ¨¡ç»„è®°å½•
                        mod_key = self.db_redesign.upsert_mod(cursor, mod_info, mod_info.get('file_hash', ''))
                        discovered_mods.add(mod_key)
                        self.db_redesign.record_scan_discovery(cursor, scan_id, mod_key, 'mod')
                        
                        # å¤„ç†è¯­è¨€æ–‡ä»¶
                        for lang_file in language_files:
                            if 'entries' in lang_file:
                                lang_file_hash = self.db_redesign.upsert_language_file(
                                    cursor, mod_key, lang_file, lang_file['entries']
                                )
                                discovered_language_files.add(lang_file_hash)
                                self.db_redesign.record_scan_discovery(cursor, scan_id, lang_file_hash, 'language_file')
                                
                                self.db_redesign.upsert_translation_entries(
                                    cursor, lang_file_hash, lang_file['entries']
                                )
                                discovered_translations += len(lang_file['entries'])
                    
                    # æ¯5ä¸ªæ–‡ä»¶æäº¤ä¸€æ¬¡
                    if (file_index + 1) % 5 == 0:
                        conn.commit()
                
                # è®©å‡ºCPUæ—¶é—´
                await asyncio.sleep(0.1)
            
            # å®Œæˆæ‰«æ
            final_progress = {
                "status": "completed",
                "progress": 100,
                "total_files": len(jar_files),
                "processed_files": len(jar_files),
                "total_mods": len(discovered_mods),
                "total_language_files": len(discovered_language_files),
                "total_keys": discovered_translations,
                "completed_at": datetime.now().isoformat()
            }
            
            # æ›´æ–°æ•°æ®åº“
            cursor.execute("""
                UPDATE scan_sessions 
                SET status = 'completed', completed_at = ?, 
                    total_mods = ?, total_language_files = ?, total_keys = ?
                WHERE id = ?
            """, (
                final_progress["completed_at"],
                final_progress["total_mods"],
                final_progress["total_language_files"],
                final_progress["total_keys"],
                scan_id
            ))
            
            conn.commit()
            conn.close()
            
            # æ›´æ–°å†…å­˜çŠ¶æ€
            self.active_scans[scan_id].update(final_progress)
            
            # çŠ¶æ€æœºå®Œæˆ
            if self.state_machine:
                await self.state_machine.complete_scan(scan_id)
            
            # å‘é€æœ€ç»ˆæ›´æ–°
            if self.ws_manager:
                await self.ws_manager.broadcast_message(
                    ProgressMessage(
                        job_id=scan_id,
                        status="completed",
                        progress=100,
                        message=f"æ‰«æå®Œæˆ! å‘ç° {len(discovered_mods)} ä¸ªæ¨¡ç»„ï¼Œ{len(discovered_language_files)} ä¸ªè¯­è¨€æ–‡ä»¶ï¼Œ{discovered_translations} ä¸ªç¿»è¯‘æ¡ç›®"
                    )
                )
            
            logger.info(f"ğŸ‰ ä¼ä¸šçº§æ‰«æå®Œæˆ: {scan_id}")
            logger.info(f"ğŸ“Š ç»Ÿè®¡: {len(discovered_mods)} æ¨¡ç»„, {len(discovered_language_files)} è¯­è¨€æ–‡ä»¶, {discovered_translations} ç¿»è¯‘æ¡ç›®")
            
        except Exception as e:
            logger.error(f"ä¼ä¸šçº§æ‰«æå¤±è´¥: {e}")
            self.active_scans[scan_id] = {"status": "failed", "error": str(e)}
            
            if self.state_machine:
                await self.state_machine.fail_scan(scan_id, str(e))
            
            if self.ws_manager:
                await self.ws_manager.broadcast_message(
                    ProgressMessage(
                        job_id=scan_id,
                        status="failed", 
                        progress=0,
                        message=f"æ‰«æå¤±è´¥: {str(e)}"
                    )
                )
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.cache_manager:
            return {"cache_enabled": False}
        
        return {
            "cache_enabled": True,
            "providers": list(self.cache_manager._providers.keys()),
            "default_provider": self.cache_manager._default_provider.__class__.__name__ if self.cache_manager._default_provider else None,
            # å¯ä»¥æ·»åŠ æ›´å¤šç»Ÿè®¡ä¿¡æ¯
        }
    
    def get_enterprise_status(self) -> Dict[str, Any]:
        """è·å–ä¼ä¸šçº§åŠŸèƒ½çŠ¶æ€"""
        return {
            "enterprise_features_available": HAS_ENTERPRISE_FEATURES,
            "jar_scanner": bool(self.jar_scanner),
            "websocket_manager": bool(self.ws_manager), 
            "cache_manager": bool(self.cache_manager),
            "state_machine": bool(self.state_machine),
            "intelligent_parsers": bool(self.mod_analyzer),
            "cache_stats": self.get_cache_stats()
        }

# å…¨å±€å®ä¾‹
enterprise_scanner = EnterpriseUpsertScanner()

if __name__ == "__main__":
    import asyncio
    
    async def test_enterprise_scanner():
        """æµ‹è¯•ä¼ä¸šçº§æ‰«æå™¨"""
        print("ğŸš€ æµ‹è¯•ä¼ä¸šçº§UPSERTæ‰«æå™¨")
        
        status = enterprise_scanner.get_enterprise_status()
        print(f"ä¼ä¸šçº§åŠŸèƒ½çŠ¶æ€: {status}")
        
        # æ¨¡æ‹Ÿæ‰«æ
        scan_id = enterprise_scanner.start_scan(".", incremental=True)
        print(f"å¯åŠ¨ä¼ä¸šçº§æ‰«æ: {scan_id}")
        
        await enterprise_scanner.scan_directory_with_enterprise_features(
            scan_id, ".", incremental=True
        )
        
        print("ä¼ä¸šçº§æ‰«ææµ‹è¯•å®Œæˆ")
    
    asyncio.run(test_enterprise_scanner())