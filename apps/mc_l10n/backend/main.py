"""
MC L10n FastAPIåº”ç”¨ä¸»å…¥å£ç‚¹

å¯åŠ¨Minecraftæœ¬åœ°åŒ–å·¥å…·çš„åç«¯APIæœåŠ¡
"""

import os
import sys
from contextlib import asynccontextmanager
from typing import Any
import uuid
import sqlite3
import asyncio
from datetime import datetime
from pathlib import Path
import hashlib
import zipfile
import json
from collections import defaultdict
import logging

from dotenv import load_dotenv
from fastapi import FastAPI, BackgroundTasks, HTTPException
from pydantic import BaseModel

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
from fastapi.openapi.docs import get_redoc_html, get_swagger_ui_html
from fastapi.openapi.utils import get_openapi

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(
    0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
)

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡å­˜å‚¨æ‰«æçŠ¶æ€
active_scans = {}

# æ•°æ®æ¨¡å‹
class ScanRequest(BaseModel):
    directory: str
    incremental: bool = True

from api.middleware.cors_config import setup_cors
from api.middleware.error_handler import setup_error_handlers
# from api.routes import transhub  # æš‚æ—¶æ³¨é‡Šæ‰æœ‰é—®é¢˜çš„å¯¼å…¥

# ä¸­é—´ä»¶å¯¼å…¥
from api.middleware.logging_middleware import LoggingMiddleware
from api.routes.mod_routes import router as mod_router

# APIè·¯ç”±å¯¼å…¥
from api.routes.project_routes import router as project_router
from api.routes.scan_routes import router as scan_router
from api.routes.translation_routes import router as translation_router

# åŸºç¡€è®¾æ–½åˆå§‹åŒ–
from infrastructure import initialize_infrastructure

from packages.core.framework.logging import StructLogFactory

# å¯¼å…¥ç®€å•çš„æ‰«ææœåŠ¡
from ddd_scanner import init_ddd_scanner, get_scanner

logger = StructLogFactory.get_logger(__name__)

# å…¨å±€æ‰«ææœåŠ¡å®ä¾‹
_scanner_service = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global _scanner_service
    
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    logger.info("MC L10n APIæœåŠ¡å¯åŠ¨ä¸­...")

    try:
        # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        from init_db import init_database
        logger.info("æ£€æŸ¥å¹¶åˆå§‹åŒ–æ•°æ®åº“...")
        init_database()
        
        # åˆå§‹åŒ–åŸºç¡€è®¾æ–½
        logger.info("åˆå§‹åŒ–åŸºç¡€è®¾æ–½ç»„ä»¶...")
        initialize_infrastructure()

        # åˆå§‹åŒ–ç®€å•æ‰«ææœåŠ¡
        global _scanner_service
        logger.info("åˆå§‹åŒ–ç®€å•æ‰«ææœåŠ¡...")
        _scanner_service = await init_ddd_scanner("mc_l10n.db")

        logger.info("MC L10n APIæœåŠ¡å¯åŠ¨å®Œæˆ")

        yield  # åº”ç”¨è¿è¡ŒæœŸé—´

    except Exception as e:
        logger.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {str(e)}")
        raise
    finally:
        # å…³é—­æ—¶æ‰§è¡Œ
        logger.info("MC L10n APIæœåŠ¡å…³é—­ä¸­...")

        # æ¸…ç†èµ„æº
        _scanner_service = None

        logger.info("MC L10n APIæœåŠ¡å…³é—­å®Œæˆ")


# åˆ›å»ºFastAPIåº”ç”¨å®ä¾‹
def create_app() -> FastAPI:
    """åˆ›å»ºå¹¶é…ç½®FastAPIåº”ç”¨"""

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    debug_mode = os.getenv("DEBUG", "false").lower() == "true"
    environment = os.getenv("ENVIRONMENT", "production").lower()

    # åˆ›å»ºåº”ç”¨å®ä¾‹
    app = FastAPI(
        title="MC L10n API",
        description="Minecraftæœ¬åœ°åŒ–å·¥å…·åç«¯APIæœåŠ¡",
        version="1.0.0",
        debug=debug_mode,
        lifespan=lifespan,
        docs_url=None,  # è‡ªå®šä¹‰æ–‡æ¡£è·¯å¾„
        redoc_url=None,
        openapi_url="/api/v1/openapi.json",
    )

    # è®¾ç½®CORS
    setup_cors(app)

    # è®¾ç½®å…¨å±€é”™è¯¯å¤„ç†
    setup_error_handlers(app)

    # æ·»åŠ æ—¥å¿—ä¸­é—´ä»¶
    app.add_middleware(
        LoggingMiddleware,
        log_request_body=False,  # æš‚æ—¶ç¦ç”¨è¯·æ±‚ä½“æ—¥å¿—ï¼Œé¿å…è¯·æ±‚ä½“è¯»å–å†²çª
        log_response_body=debug_mode,
        exclude_paths=[
            "/health",
            "/metrics",
            "/docs",
            "/redoc",
            "/openapi.json",
            "/api/v1/openapi.json",
        ],
    )

    # æ³¨å†Œè·¯ç”±
    app.include_router(project_router)
    app.include_router(mod_router)
    app.include_router(scan_router)
    app.include_router(translation_router)
    # app.include_router(transhub.router)  # Trans-Hubé›†æˆè·¯ç”± - æš‚æ—¶ç¦ç”¨
    
    # æ·»åŠ å…¨å±€çš„æ‰«æç»“æœè·¯ç”±
    @app.get("/scan-results/{scan_id}")
    async def get_scan_results_global(scan_id: str):
        """è·å–æ‰«æç»“æœï¼ˆå…¨å±€è·¯ç”±ï¼‰"""
        from ddd_scanner import get_scanner
        
        scanner_service = get_scanner()
        if not scanner_service:
            return {
                "success": False,
                "error": {
                    "code": "NO_SCANNER",
                    "message": "Scanner service not initialized"
                }
            }
        
        status = await scanner_service.get_scan_status(scan_id)
        if not status:
            return {
                "success": False,
                "error": {
                    "code": "NOT_FOUND",
                    "message": f"Scan not found: {scan_id}"
                }
            }
        
        statistics = status.get("statistics", {})
        return {
            "success": True,
            "data": {
                "scan_id": scan_id,
                "status": status.get("status"),
                "statistics": statistics,
                "total_mods": statistics.get("total_mods", 0),
                "total_language_files": statistics.get("total_language_files", 0),
                "total_keys": statistics.get("total_keys", 0),
                "entries": {},
                "errors": [],
                "warnings": []
            }
        }
    
    # æ‰«æç›¸å…³å‡½æ•°
    def init_database():
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect("mc_l10n.db")
        cursor = conn.cursor()
        
        # åˆ›å»ºæ‰«æä¼šè¯è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS scan_sessions (
                id TEXT PRIMARY KEY,
                directory TEXT NOT NULL,
                started_at TEXT NOT NULL,
                completed_at TEXT,
                status TEXT DEFAULT 'scanning',
                total_mods INTEGER DEFAULT 0,
                total_language_files INTEGER DEFAULT 0,
                total_keys INTEGER DEFAULT 0,
                scan_mode TEXT DEFAULT 'å…¨é‡'
            )
        """)
        
        # åˆ›å»ºæ¨¡ç»„ä¿¡æ¯è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS mods (
                id TEXT PRIMARY KEY,
                scan_id TEXT,
                mod_id TEXT,
                display_name TEXT,
                version TEXT,
                file_path TEXT,
                size INTEGER,
                mod_loader TEXT,
                description TEXT,
                authors TEXT,
                FOREIGN KEY (scan_id) REFERENCES scan_sessions(id),
                UNIQUE(mod_id, file_path)
            )
        """)
        
        # åˆ›å»ºè¯­è¨€æ–‡ä»¶è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS language_files (
                id TEXT PRIMARY KEY,
                scan_id TEXT,
                mod_id TEXT,
                namespace TEXT,
                locale TEXT,
                file_path TEXT,
                key_count INTEGER,
                FOREIGN KEY (scan_id) REFERENCES scan_sessions(id),
                UNIQUE(namespace, locale, file_path)
            )
        """)
        
        # åˆ›å»ºç¿»è¯‘æ¡ç›®è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS translation_entries (
                id TEXT PRIMARY KEY,
                language_file_id TEXT,
                key TEXT,
                value TEXT,
                FOREIGN KEY (language_file_id) REFERENCES language_files(id),
                UNIQUE(language_file_id, key)
            )
        """)
        
        # åˆ›å»ºæ–‡ä»¶å“ˆå¸Œè¡¨ï¼Œç”¨äºå¢é‡æ‰«æ
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS file_hashes (
                file_path TEXT PRIMARY KEY,
                file_hash TEXT NOT NULL,
                last_modified TIMESTAMP NOT NULL,
                file_size INTEGER NOT NULL,
                last_scanned TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # åˆ›å»ºå”¯ä¸€ç´¢å¼•ä»¥é˜²æ­¢é‡å¤æ•°æ®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        try:
            cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_mods_unique ON mods(mod_id, file_path)")
            cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_language_files_unique ON language_files(namespace, locale, file_path)")
        except Exception as e:
            # ç´¢å¼•å¯èƒ½å·²å­˜åœ¨æˆ–æœ‰å†²çªæ•°æ®ï¼Œå¿½ç•¥é”™è¯¯
            print(f"åˆ›å»ºå”¯ä¸€ç´¢å¼•æ—¶å‡ºç°è­¦å‘Šï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
        
        conn.commit()
        conn.close()
    
    def parse_mod_jar(jar_path: Path):
        """ç®€åŒ–çš„JARè§£æå‡½æ•°"""
        try:
            mod_info = {"mod_id": jar_path.stem, "name": jar_path.stem}
            language_files = []
            
            with zipfile.ZipFile(jar_path, 'r') as jar:
                for file_info in jar.filelist:
                    file_path = file_info.filename
                    if '/lang/' in file_path and file_path.endswith('.json'):
                        # æå–è¯­è¨€ä»£ç 
                        lang_file = file_path.split('/')[-1]
                        locale = lang_file.replace('.json', '')
                        
                        try:
                            with jar.open(file_info) as f:
                                content = json.load(f)
                                if isinstance(content, dict):
                                    language_files.append({
                                        "file_path": file_path,
                                        "locale": locale,
                                        "key_count": len(content),
                                        "namespace": file_path.split('/')[1] if '/' in file_path else 'minecraft',
                                        "entries": content  # æ·»åŠ å®é™…çš„ç¿»è¯‘æ¡ç›®æ•°æ®
                                    })
                        except:
                            pass  # å¿½ç•¥è§£æå¤±è´¥çš„æ–‡ä»¶
            
            return mod_info, language_files
        except Exception as e:
            logger.error(f"è§£æJARå¤±è´¥ {jar_path}: {e}")
            return None, []
    
    async def scan_directory_real(scan_id: str, directory: str, incremental: bool = True):
        """å®é™…æ‰«æç›®å½•å‡½æ•°"""
        logger.info(f"å¼€å§‹{'å¢é‡' if incremental else 'å…¨é‡'}æ‰«æç›®å½•: {directory}")
        
        try:
            scan_path = Path(directory)
            if not scan_path.exists():
                raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
            
            # æŸ¥æ‰¾æ‰€æœ‰jaræ–‡ä»¶
            jar_files = []
            for root, dirs, files in os.walk(scan_path):
                for file in files:
                    if file.endswith('.jar'):
                        jar_files.append(Path(root) / file)
            
            # æ›´æ–°æ‰«æçŠ¶æ€
            active_scans[scan_id] = {
                "status": "scanning", 
                "progress": 0,
                "total_files": len(jar_files),
                "processed_files": 0,
                "current_file": "",
                "total_mods": 0,
                "total_language_files": 0,
                "total_keys": 0,
                "scan_mode": "å¢é‡" if incremental else "å…¨é‡",
                "started_at": datetime.now().isoformat()
            }
            
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œç»Ÿè®¡
            conn = sqlite3.connect("mc_l10n.db")
            cursor = conn.cursor()
            
            total_mods = 0
            total_language_files = 0
            total_keys = 0
            
            for i, jar_path in enumerate(jar_files):
                # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if scan_id in active_scans and active_scans[scan_id].get("status") == "cancelled":
                    logger.info(f"æ‰«æè¢«å–æ¶ˆ: {scan_id}")
                    conn.close()
                    return
                
                # æ›´æ–°å½“å‰å¤„ç†çš„æ–‡ä»¶
                active_scans[scan_id]["current_file"] = jar_path.name
                active_scans[scan_id]["processed_files"] = i + 1
                active_scans[scan_id]["progress"] = ((i + 1) / len(jar_files)) * 100
                
                logger.info(f"æ­£åœ¨å¤„ç† ({i+1}/{len(jar_files)}): {jar_path.name}")
                
                try:
                    mod_info, language_files = parse_mod_jar(jar_path)
                    
                    if mod_info:
                        # å­˜å‚¨æ¨¡ç»„ä¿¡æ¯
                        mod_id = str(uuid.uuid4())
                        cursor.execute("""
                            INSERT OR IGNORE INTO mods (id, scan_id, mod_id, display_name, version, file_path, size)
                            VALUES (?, ?, ?, ?, ?, ?, ?)
                        """, (
                            mod_id, scan_id, mod_info.get('mod_id', jar_path.stem),
                            mod_info.get('name', jar_path.stem), mod_info.get('version', 'æœªçŸ¥'),
                            str(jar_path), jar_path.stat().st_size if jar_path.exists() else 0
                        ))
                        total_mods += 1
                        
                        # å­˜å‚¨è¯­è¨€æ–‡ä»¶å’Œç¿»è¯‘æ¡ç›®
                        for lang_file in language_files:
                            lang_file_id = str(uuid.uuid4())
                            cursor.execute("""
                                INSERT OR IGNORE INTO language_files (id, scan_id, mod_id, namespace, locale, file_path, key_count)
                                VALUES (?, ?, ?, ?, ?, ?, ?)
                            """, (
                                lang_file_id, scan_id, mod_info.get('mod_id', jar_path.stem),
                                lang_file.get('namespace', 'minecraft'), lang_file.get('locale', 'en_us'),
                                lang_file.get('file_path', ''), lang_file.get('key_count', 0)
                            ))
                            
                            # å­˜å‚¨ç¿»è¯‘æ¡ç›®
                            if 'entries' in lang_file:
                                for key, value in lang_file['entries'].items():
                                    if isinstance(value, str):
                                        stored_value = value
                                    else:
                                        stored_value = str(value)
                                    
                                    cursor.execute("""
                                        INSERT OR IGNORE INTO translation_entries (id, language_file_id, key, value)
                                        VALUES (?, ?, ?, ?)
                                    """, (str(uuid.uuid4()), lang_file_id, key, stored_value))
                            
                            total_language_files += 1
                            total_keys += lang_file.get('key_count', 0)
                        
                        # æ¯å¤„ç†5ä¸ªæ–‡ä»¶æäº¤ä¸€æ¬¡
                        if (i + 1) % 5 == 0:
                            conn.commit()
                
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶ {jar_path} æ—¶å‡ºé”™: {e}")
                    continue
                
                # æ¯10ä¸ªæ–‡ä»¶ä¼‘æ¯ä¸€ä¸‹ï¼Œé¿å…é˜»å¡
                if i % 10 == 0:
                    await asyncio.sleep(0.1)
            
            cursor.execute("""
                UPDATE scan_sessions 
                SET status = 'completed', completed_at = ?, total_mods = ?, 
                    total_language_files = ?, total_keys = ?
                WHERE id = ?
            """, (datetime.now().isoformat(), total_mods, total_language_files, total_keys, scan_id))
            conn.commit()
            conn.close()
            
            # æ›´æ–°å†…å­˜çŠ¶æ€
            completion_data = {
                "status": "completed",
                "progress": 100,
                "total_files": len(jar_files),
                "processed_files": len(jar_files),
                "total_mods": total_mods,
                "total_language_files": total_language_files,
                "total_keys": total_keys,
                "completed_at": datetime.now().isoformat()
            }
            active_scans[scan_id].update(completion_data)
            
            logger.info(f"æ‰«æå®Œæˆ: {scan_id}, å‘ç°{total_mods}ä¸ªæ¨¡ç»„ï¼Œ{total_language_files}ä¸ªè¯­è¨€æ–‡ä»¶ï¼Œ{total_keys}ä¸ªæ¡ç›®")
            
        except Exception as e:
            logger.error(f"æ‰«æå¤±è´¥: {e}")
            active_scans[scan_id] = {"status": "failed", "error": str(e)}
            
            conn = sqlite3.connect("mc_l10n.db")
            cursor = conn.cursor()
            cursor.execute("UPDATE scan_sessions SET status = 'failed' WHERE id = ?", (scan_id,))
            conn.commit()
            conn.close()
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()
    
    # å…¼å®¹æ€§ç«¯ç‚¹
    from fastapi import APIRouter
    compat_router = APIRouter()
    
    @compat_router.get("/api/v1/scan-project-test-get")
    async def scan_project_test_get():
        """GETæµ‹è¯•ç«¯ç‚¹"""
        return {"success": True, "message": "GET test endpoint working"}
    
    @compat_router.post("/api/v1/scan-project-test")
    async def scan_project_test():
        """æœ€ç®€å•çš„æµ‹è¯•ç«¯ç‚¹"""
        return {"success": True, "message": "test endpoint working"}
    
    @compat_router.post("/api/v1/scan-project-test-json")
    async def scan_project_test_json(request: dict):
        """æµ‹è¯•JSONè§£æ"""
        return {"success": True, "received": request}
    
    @compat_router.post("/api/v1/scan-project")
    async def scan_project_v1_compat(request: ScanRequest):
        """ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡çš„æ‰«æç«¯ç‚¹"""
        global _scanner_service
        
        try:
            # æå–å‚æ•°
            directory = request.directory
            incremental = request.incremental
            
            if not directory:
                raise ValueError("directoryå‚æ•°æ˜¯å¿…éœ€çš„")
            
            if not _scanner_service:
                raise HTTPException(status_code=500, detail="æ‰«ææœåŠ¡æœªåˆå§‹åŒ–")
            
            # ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡å¯åŠ¨æ‰«æ
            scan_info = await _scanner_service.start_scan(
                target_path=directory,
                incremental=incremental,
                options={}
            )
            
            return {
                "success": True,
                "message": f"æ‰«æå·²å¼€å§‹: {directory} (ä½¿ç”¨ç»Ÿä¸€æ‰«æå¼•æ“)",
                "job_id": scan_info["scan_id"],
                "scan_id": scan_info["scan_id"]
            }
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ç»Ÿä¸€æ‰«æå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=str(e))
    
    @compat_router.get("/api/v1/scan-status/{scan_id}")
    async def get_scan_status_v1_compat(scan_id: str):
        """ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡è·å–æ‰«æçŠ¶æ€"""
        global _scanner_service
        
        try:
            if not _scanner_service:
                return {"success": False, "message": "æ‰«ææœåŠ¡æœªåˆå§‹åŒ–"}
            
            # ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡è·å–çŠ¶æ€
            status = await _scanner_service.get_scan_status(scan_id)
            
            if status:
                # ä¿®æ­£æ—¥å¿—ä¸­çš„å­—æ®µè®¿é—®
                logger.info(f"è¿”å›ç»Ÿä¸€æ‰«æçŠ¶æ€ {scan_id}: status={status.get('status', 'unknown')}, progress={status.get('progress', 0)}, processed={status.get('processed_files', 0)}/{status.get('total_files', 0)}")
                logger.info(f"å®Œæ•´çŠ¶æ€æ•°æ®: {status}")
                return {"success": True, "data": status}
            
            # æ‰«æä¸å­˜åœ¨
            logger.warning(f"æœªæ‰¾åˆ°æ‰«æä»»åŠ¡: {scan_id}")
            return {"success": False, "message": "æ‰«æä»»åŠ¡æœªæ‰¾åˆ°"}
                
        except Exception as e:
            logger.error(f"è·å–æ‰«æçŠ¶æ€å¤±è´¥: {e}")
            return {"success": False, "message": str(e)}
    
    @compat_router.get("/api/v1/scan-results/{scan_id}")
    async def get_scan_results_v1_compat(scan_id: str):
        """ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡è·å–æ‰«æç»“æœ"""
        global _scanner_service
        
        try:
            if not _scanner_service:
                return {"success": False, "message": "æ‰«ææœåŠ¡æœªåˆå§‹åŒ–"}
            
            # è·å–æ‰«æçŠ¶æ€ï¼Œæ£€æŸ¥æ˜¯å¦å®Œæˆ
            status = await _scanner_service.get_scan_status(scan_id)
            
            if not status:
                return {"success": False, "message": "æ‰«æä»»åŠ¡ä¸å­˜åœ¨"}
            
            if status.get("status") != "completed":
                return {"success": False, "message": "æ‰«ææœªå®Œæˆ"}
            
            # è·å–å†…å®¹é¡¹ï¼ˆæ¨¡ç»„å’Œè¯­è¨€æ–‡ä»¶ï¼‰
            mods = await _scanner_service.get_content_items(content_type="mod", limit=500)
            language_files = await _scanner_service.get_content_items(content_type="language_file", limit=1000)
            
            # å¤„ç†æ¨¡ç»„æ•°æ®
            mod_list = []
            for mod in mods:
                mod_data = {
                    "id": mod.get("content_hash", "")[:8],
                    "name": mod.get("name", "Unknown Mod"),
                    "mod_id": mod.get("metadata", {}).get("mod_id", ""),
                    "version": mod.get("metadata", {}).get("version", ""),
                    "file_path": mod.get("metadata", {}).get("file_path", ""),
                    "language_files": 0,
                    "total_keys": 0
                }
                # ç»Ÿè®¡è¯¥æ¨¡ç»„çš„è¯­è¨€æ–‡ä»¶æ•°
                for lf in language_files:
                    if lf.get("relationships", {}).get("mod_hash") == mod.get("content_hash"):
                        mod_data["language_files"] += 1
                        mod_data["total_keys"] += lf.get("metadata", {}).get("key_count", 0)
                mod_list.append(mod_data)
            
            # å¤„ç†è¯­è¨€æ–‡ä»¶æ•°æ®
            lf_list = []
            for lf in language_files[:100]:  # é™åˆ¶è¿”å›å‰100ä¸ª
                lf_list.append({
                    "id": lf.get("content_hash", "")[:8],
                    "file_name": lf.get("name", ""),
                    "language": lf.get("metadata", {}).get("language", "en_us"),
                    "key_count": lf.get("metadata", {}).get("key_count", 0),
                    "mod_id": lf.get("relationships", {}).get("mod_id", "")
                })
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            statistics = {
                "total_mods": len(mods),
                "total_language_files": len(language_files),
                "total_keys": sum(lf.get("metadata", {}).get("key_count", 0) for lf in language_files),
                "scan_duration_ms": status.get("duration_seconds", 0) * 1000
            }
            
            return {
                "success": True,
                "data": {
                    "scan_id": scan_id,
                    "mods": mod_list,
                    "language_files": lf_list,
                    "statistics": statistics
                }
            }
                
        except Exception as e:
            logger.error(f"è·å–ç»Ÿä¸€æ‰«æç»“æœå¤±è´¥: {e}")
            return {"success": False, "message": str(e)}
    
    @compat_router.post("/api/v1/scan-cancel/{scan_id}")
    async def cancel_scan_v1_compat(scan_id: str):
        """ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡å–æ¶ˆæ‰«æ"""
        global _scanner_service
        
        try:
            if not _scanner_service:
                return {"success": False, "message": "æ‰«ææœåŠ¡æœªåˆå§‹åŒ–"}
            
            # ä½¿ç”¨ç»Ÿä¸€æ‰«ææœåŠ¡å–æ¶ˆæ‰«æ
            success = await _scanner_service.cancel_scan(scan_id)
            
            if success:
                logger.info(f"ç»Ÿä¸€æ‰«æå·²å–æ¶ˆ: {scan_id}")
                return {"success": True, "message": "æ‰«æå·²å–æ¶ˆ"}
            else:
                return {"success": False, "message": "æ‰«æä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å®Œæˆ"}
                
        except Exception as e:
            logger.error(f"å–æ¶ˆç»Ÿä¸€æ‰«æå¤±è´¥: {e}")
            return {"success": False, "message": str(e)}
    
    @compat_router.get("/api/v1/scans/active")
    async def get_active_scans():
        """è·å–æ´»è·ƒçš„æ‰«æçŠ¶æ€"""
        try:
            active_scan_list = []
            for scan_id, scan_status in active_scans.items():
                active_scan_list.append({
                    "id": scan_id,
                    "status": scan_status.get("status", "unknown"),
                    "progress": scan_status.get("progress", 0),
                    "processed_files": scan_status.get("processed_files", 0),
                    "total_files": scan_status.get("total_files", 0),
                    "current_file": scan_status.get("current_file", ""),
                    "total_mods": scan_status.get("total_mods", 0),
                    "total_language_files": scan_status.get("total_language_files", 0),
                    "total_keys": scan_status.get("total_keys", 0),
                    "scan_mode": scan_status.get("scan_mode", "æœªçŸ¥"),
                    "started_at": scan_status.get("started_at", "")
                })
            
            return {
                "success": True,
                "data": active_scan_list
            }
        except Exception as e:
            logger.error(f"è·å–æ´»è·ƒæ‰«æå¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    app.include_router(compat_router)
    
    # ç›´æ¥åœ¨appä¸Šæ·»åŠ æµ‹è¯•è·¯ç”±
    @app.get("/api/v1/direct-test")
    async def direct_test():
        return {"success": True, "message": "Direct route working"}

    # æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
    @app.get("/health", tags=["ç³»ç»Ÿ"], summary="å¥åº·æ£€æŸ¥")
    async def health_check() -> dict[str, Any]:
        """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        return {
            "status": "healthy",
            "service": "mc-l10n-api",
            "version": "1.0.0",
            "environment": environment,
            "timestamp": "2024-12-30T12:00:00",  # ç®€åŒ–å®ç°
        }

    # æ·»åŠ ç³»ç»Ÿä¿¡æ¯ç«¯ç‚¹
    @app.get("/info", tags=["ç³»ç»Ÿ"], summary="ç³»ç»Ÿä¿¡æ¯")
    async def system_info() -> dict[str, Any]:
        """ç³»ç»Ÿä¿¡æ¯ç«¯ç‚¹"""
        import platform

        return {
            "service": {
                "name": "MC L10n API",
                "version": "1.0.0",
                "environment": environment,
                "debug_mode": debug_mode,
            },
            "system": {
                "platform": platform.platform(),
                "python_version": platform.python_version(),
            },
            "api": {
                "total_routes": len(app.routes),
                "cors_enabled": True,
                "error_handling": True,
                "request_logging": True,
            },
        }

    # è‡ªå®šä¹‰OpenAPIæ–‡æ¡£
    def custom_openapi():
        if app.openapi_schema:
            return app.openapi_schema

        openapi_schema = get_openapi(
            title="MC L10n API",
            version="1.0.0",
            description="""
# Minecraftæœ¬åœ°åŒ–å·¥å…·API

è¿™æ˜¯ä¸€ä¸ªç”¨äºMinecraftæ¨¡ç»„å’Œèµ„æºåŒ…æœ¬åœ°åŒ–çš„å®Œæ•´APIæœåŠ¡ã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¯ é¡¹ç›®ç®¡ç†
- åˆ›å»ºå’Œç®¡ç†ç¿»è¯‘é¡¹ç›®
- é¡¹ç›®é…ç½®å’Œè®¾ç½®
- é¡¹ç›®è¿›åº¦ç»Ÿè®¡

### ğŸ“¦ æ¨¡ç»„ç®¡ç†
- æ‰«æå’Œåˆ†æJAR/æ–‡ä»¶å¤¹
- è§£ææ¨¡ç»„å…ƒæ•°æ®
- ä¾èµ–å…³ç³»ç®¡ç†

### ğŸŒ ç¿»è¯‘ç®¡ç†
- ç¿»è¯‘æ¡ç›®æå–
- å¤šæ ¼å¼å¯¼å…¥/å¯¼å‡º
- æ‰¹é‡ç¿»è¯‘æ“ä½œ
- ç¿»è¯‘è¿›åº¦è·Ÿè¸ª

### ğŸ” æœç´¢åŠŸèƒ½
- é¡¹ç›®æœç´¢
- æ¨¡ç»„æœç´¢
- ç¿»è¯‘å†…å®¹æœç´¢

## APIç‰ˆæœ¬

å½“å‰ç‰ˆæœ¬: **v1.0.0**

æ‰€æœ‰APIç«¯ç‚¹éƒ½ä»¥ `/api/v1/` å¼€å¤´ã€‚

## è®¤è¯

ç›®å‰APIå¤„äºå¼€å‘é˜¶æ®µï¼Œæš‚ä¸éœ€è¦è®¤è¯ã€‚ç”Ÿäº§ç¯å¢ƒå°†ä½¿ç”¨JWT tokenè®¤è¯ã€‚

## å“åº”æ ¼å¼

æ‰€æœ‰APIå“åº”éƒ½éµå¾ªç»Ÿä¸€æ ¼å¼ï¼š

```json
{
  "success": true,
  "data": { ... },
  "message": "æ“ä½œæˆåŠŸ",
  "request_id": "req_12345678"
}
```

é”™è¯¯å“åº”æ ¼å¼ï¼š

```json
{
  "success": false,
  "error": {
    "code": "ERROR_CODE",
    "message": "é”™è¯¯æè¿°",
    "details": { ... }
  },
  "request_id": "req_12345678"
}
```
            """,
            routes=app.routes,
        )

        # æ·»åŠ è‡ªå®šä¹‰ä¿¡æ¯
        openapi_schema["info"]["x-logo"] = {
            "url": "https://fastapi.tiangolo.com/img/logo-margin/logo-teal.png"
        }

        app.openapi_schema = openapi_schema
        return app.openapi_schema

    app.openapi = custom_openapi

    # è‡ªå®šä¹‰æ–‡æ¡£é¡µé¢
    @app.get("/docs", include_in_schema=False)
    async def custom_swagger_ui_html():
        return get_swagger_ui_html(
            openapi_url=app.openapi_url,
            title=f"{app.title} - Swagger UI",
            oauth2_redirect_url=app.swagger_ui_oauth2_redirect_url,
            swagger_js_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@5/swagger-ui-bundle.js",
            swagger_css_url="https://cdn.jsdelivr.net/npm/swagger-ui-dist@5/swagger-ui.css",
        )

    @app.get("/redoc", include_in_schema=False)
    async def redoc_html():
        return get_redoc_html(
            openapi_url=app.openapi_url,
            title=f"{app.title} - ReDoc",
            redoc_js_url="https://cdn.jsdelivr.net/npm/redoc@2.1.0/bundles/redoc.standalone.js",
        )

    return app


# åˆ›å»ºåº”ç”¨å®ä¾‹
app = create_app()


# å¯åŠ¨é…ç½®
if __name__ == "__main__":
    import uvicorn

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®ï¼Œä½¿ç”¨ä¸å¸¸è§çš„ç«¯å£é¿å…å†²çª
    host = os.getenv("HOST", "127.0.0.1")
    port = int(os.getenv("PORT", "18000"))  # ä½¿ç”¨18000ç«¯å£ï¼Œé¿å…ä¸å…¶ä»–æœåŠ¡å†²çª
    debug = os.getenv("DEBUG", "false").lower() == "true"
    reload = os.getenv("RELOAD", "true" if debug else "false").lower() == "true"
    workers = int(os.getenv("WORKERS", "1"))

    logger.info(f"å¯åŠ¨MC L10n APIæœåŠ¡: http://{host}:{port}")
    logger.info(f"è°ƒè¯•æ¨¡å¼: {debug}, è‡ªåŠ¨é‡è½½: {reload}, å·¥ä½œè¿›ç¨‹: {workers}")
    logger.info(f"APIæ–‡æ¡£: http://{host}:{port}/docs")
    logger.info(f"ReDocæ–‡æ¡£: http://{host}:{port}/redoc")

    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=reload,
        workers=workers if not debug else 1,  # è°ƒè¯•æ¨¡å¼ä¸‹åªä½¿ç”¨1ä¸ªå·¥ä½œè¿›ç¨‹
        access_log=True,
        use_colors=True,
        log_config={
            "version": 1,
            "disable_existing_loggers": False,
            "formatters": {
                "default": {
                    "()": "uvicorn.logging.DefaultFormatter",
                    "fmt": "%(levelprefix)s %(asctime)s %(message)s",
                    "datefmt": "%Y-%m-%d %H:%M:%S",
                },
                "access": {
                    "()": "uvicorn.logging.AccessFormatter",
                    "fmt": '%(levelprefix)s %(client_addr)s - "%(request_line)s" %(status_code)s',
                },
            },
            "handlers": {
                "default": {
                    "formatter": "default",
                    "class": "logging.StreamHandler",
                    "stream": "ext://sys.stdout",
                },
                "access": {
                    "formatter": "access",
                    "class": "logging.StreamHandler",
                    "stream": "ext://sys.stdout",
                },
            },
            "loggers": {
                "uvicorn": {"level": "INFO", "handlers": ["default"], "propagate": False},
                "uvicorn.error": {"level": "INFO", "handlers": ["default"], "propagate": False},
                "uvicorn.access": {"level": "INFO", "handlers": ["access"], "propagate": False},
            },
            "root": {
                "level": "INFO",
                "handlers": ["default"],
            },
        },
    )
